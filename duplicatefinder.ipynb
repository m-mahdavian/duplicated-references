{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3xVeY7PKSUGB5YVXIlkVF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-mahdavian/duplicated-references/blob/main/duplicatefinder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Readme\n",
        "Unfortunately, using reference managers by different co-authors sometimes results in an anomaly in the reference list. Some references may be inserted in two places of the references list with the same format or with a bit of difference in the data. Although reference managers have built-in duplicate removers, when two or more co-authors are working on a manuscript, facing this problem seems inevitable. The purpose of this program is to assist authors, especially corresponding authors, in detecting duplicate references in the lengthy reference list of manuscripts before submission to a journal. You can remove the 100% match duplicates with no further consideration. However, those that are found similar might be duplicates due to different information entries in the reference managers or different due to, e.g., similar titles of similar authors lists. Therefore, in the case of susceptible duplicates remove them manually after a thorough check. I used the FuzzyWuzzy library of Python to find similarities. You can decrease the target similarity % if there is more chance of finding duplicates in your references list due to errors in reference data entry in the reference managers.\n",
        "\n",
        "To use this code, you need to copy-paste the references list into the notepad and save it as \"references.txt\". This code is compatible with most reference lists. However, with some reference list formats, a bit of change in the codes may be required. Please leave me a comment if you enjoy it, you find a glitch with some references list, or you come up with some hints to change the code. Please mention your selected similarity % in your comment.\n",
        "\n",
        "Note: Finding duplicates using duplicated() and removing them with drop_duplicates() methods seems to be ineffective sometimes which is why I didn't use them here.\n",
        "\n",
        "This code has been developed by M. Mahdavian. I have used some hints of Bing AI to develop this code.\n",
        "https://www.linkedin.com/in/mohammad-mahdavian-50827b53"
      ],
      "metadata": {
        "id": "4tbx-e_lCzgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and Loading Required Libraries"
      ],
      "metadata": {
        "id": "XmyDx_8SdWoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fuzzywuzzy[speedup]"
      ],
      "metadata": {
        "id": "TMs2DzZu6ks-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87920c6-bc8b-4d9d-a1e9-0eec2f452feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy[speedup] in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-levenshtein>=0.12 in /usr/local/lib/python3.10/dist-packages (from fuzzywuzzy[speedup]) (0.23.0)\n",
            "Requirement already satisfied: Levenshtein==0.23.0 in /usr/local/lib/python3.10/dist-packages (from python-levenshtein>=0.12->fuzzywuzzy[speedup]) (0.23.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.23.0->python-levenshtein>=0.12->fuzzywuzzy[speedup]) (3.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrylfiX4GMu4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from fuzzywuzzy import fuzz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the References Text File"
      ],
      "metadata": {
        "id": "LruxUQC-3Qc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"references.txt\", \"rb\")\n",
        "data = file.readlines()\n",
        "file.close()\n",
        "x=0\n",
        "text=[]\n",
        "while x <len(data):\n",
        "  text.append(data[x].decode(\"ISO-8859-1\"))\n",
        "  x=x+1"
      ],
      "metadata": {
        "id": "iLkwa3PZcgbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(text)"
      ],
      "metadata": {
        "id": "3xNpKkoB0he0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing the References' Number"
      ],
      "metadata": {
        "id": "pFzt2TdQdhA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "while i<len(df)+1:\n",
        "  x='['+str(i)+']'\n",
        "  df[0]=df[0].str.strip(x)\n",
        "  i=i+1"
      ],
      "metadata": {
        "id": "lbWWo42b30yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding Exact Duplicates"
      ],
      "metadata": {
        "id": "GhOu1zf-2SoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "j=0\n",
        "s=0\n",
        "duplicated=[]\n",
        "#index_of_duplicates=id\n",
        "id=[]\n",
        "while i <len(df):\n",
        "  while j<len(df):\n",
        "    if i!=j and df.iloc[i].to_string()==df.iloc[j].to_string():\n",
        "      if df.iloc[i].to_string() not in duplicated and i not in id and j not in id:\n",
        "        print(\"Ref. Number #\", i+1, \"is identical (100% similar) to Ref. Number #\", j+1)\n",
        "        duplicated.append(df.iloc[i].to_string())\n",
        "        id.append(j)\n",
        "      s=s+1\n",
        "    j=j+1\n",
        "  j=0\n",
        "  i=i+1\n",
        "if s==0:\n",
        "  print(\"NO IDENTICAL (100% SIMILAR) REFERENCES WERE DETECTED.\")"
      ],
      "metadata": {
        "id": "4-gDLmJqKyn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c61fc4-605a-42a8-9b99-b7405207ac55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ref. Number # 40 is identical (100% similar) to Ref. Number # 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing Identical Documents"
      ],
      "metadata": {
        "id": "VbB6mXFvgEp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "j=0\n",
        "while i<len(df):\n",
        "  if df.iloc[i].to_string() in duplicated:\n",
        "    #print(j)\n",
        "    del duplicated[j]\n",
        "    df.at[i, 0] = \"Mahdavian\"\n",
        "  i=i+1"
      ],
      "metadata": {
        "id": "3SbLYVPFSN14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding Near Duplicates"
      ],
      "metadata": {
        "id": "fY5spxRx2cRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "j=0\n",
        "s=0\n",
        "# Set the intended similarity % here.\n",
        "similarity=80\n",
        "id=[]\n",
        "print(\"Succeptible duplicated references cosidering similarity above or equal to\", similarity, \"%:\")\n",
        "print(\"***Remove them manually after a thorough check. You can decrease similarity % if you think \\nthere is more chance to find duplicates in your references list due to errors in references \\ninformation entry in the reference managers.***\")\n",
        "while i <len(df):\n",
        "  while j<len(df):\n",
        "    if i!=j and fuzz.ratio(df.iloc[i].to_string(), df.iloc[j].to_string())>=similarity:\n",
        "      id1=len(df.iloc[i].to_string())\n",
        "      id2=len(df.iloc[j].to_string())\n",
        "      if id1!=14 or id2!=14:\n",
        "        if i not in id and j not in id:\n",
        "          print(\"Ref. Number #\", i+1, \"is similar to Ref. Number #\", j+1)\n",
        "          id.append(j)\n",
        "        s=s+1\n",
        "    j=j+1\n",
        "  j=0\n",
        "  i=i+1\n",
        "if s==0:\n",
        "  print(\"NO SIMILARITY WAS DETECTED.\")\n"
      ],
      "metadata": {
        "id": "N7K_FhIeKin0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45dde651-f921-4acb-b776-2ed9ed7ecff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succeptible duplicated references cosidering similarity above or equal to 80 %:\n",
            "***Remove them manually after a thorough check. You can decrease similarity % if you think \n",
            "there is more chance to find duplicates in your references list due to errors in references \n",
            "information entry in the reference managers.***\n",
            "NO SIMILARITY WAS DETECTED.\n"
          ]
        }
      ]
    }
  ]
}